{"cells":[{"cell_type":"markdown","metadata":{"id":"Q-Nm2wE5BLyQ"},"source":["## Prefix-Tuning GPT-2 Medium Model\n","\n"]},{"cell_type":"markdown","source":["### Import & Setup:"],"metadata":{"id":"7wz9IqvpKnZE"}},{"cell_type":"code","source":["import os, sys"],"metadata":{"id":"L1y7-cfxBSLW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwTvMlbABT6B","executionInfo":{"status":"ok","timestamp":1702202760024,"user_tz":480,"elapsed":13161,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"d284a4e9-9d85-43a7-d6ac-6ab7100dab75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["os.chdir('drive/MyDrive/cmpt413_proj')"],"metadata":{"id":"vawOmjvuBwMq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"id":"9PI8W-hhBsMv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702202786867,"user_tz":480,"elapsed":26233,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"8b44cd59-4cc8-4a12-b73d-76328f5cdd02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (23.1.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.42.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (67.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.23.5)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (6.5.5)\n","Collecting jupyter_contrib_nbextensions (from -r requirements.txt (line 6))\n","  Downloading jupyter_contrib_nbextensions-0.7.0.tar.gz (23.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jupyter_nbextensions_configurator (from -r requirements.txt (line 7))\n","  Downloading jupyter_nbextensions_configurator-0.6.3-py2.py3-none-any.whl (466 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.9/466.9 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.35.2)\n","Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.1.0+cu118)\n","Collecting datasets~=2.12.0 (from -r requirements.txt (line 10))\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.66.1)\n","Collecting sacrebleu (from -r requirements.txt (line 12))\n","  Downloading sacrebleu-2.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate (from -r requirements.txt (line 13))\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting peft (from -r requirements.txt (line 14))\n","  Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 13)) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 13)) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 13)) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 13)) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 13)) (0.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (3.1.2)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (6.3.2)\n","Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (23.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (23.1.0)\n","Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (5.7.1)\n","Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (5.5.0)\n","Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (6.1.12)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (0.2.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (5.9.2)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (6.5.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (1.5.8)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (5.5.6)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (1.8.2)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (0.18.0)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (0.19.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->-r requirements.txt (line 5)) (1.0.0)\n","Collecting jupyter_contrib_core>=0.3.3 (from jupyter_contrib_nbextensions->-r requirements.txt (line 6))\n","  Downloading jupyter_contrib_core-0.4.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jupyter_highlight_selected_word>=0.1.1 (from jupyter_contrib_nbextensions->-r requirements.txt (line 6))\n","  Downloading jupyter_highlight_selected_word-0.2.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_nbextensions->-r requirements.txt (line 6)) (4.9.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (3.13.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (0.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (3.2.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (2.1.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.12.0->-r requirements.txt (line 10)) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets~=2.12.0->-r requirements.txt (line 10))\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets~=2.12.0->-r requirements.txt (line 10)) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets~=2.12.0->-r requirements.txt (line 10)) (3.4.1)\n","Collecting multiprocess (from datasets~=2.12.0->-r requirements.txt (line 10))\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets~=2.12.0->-r requirements.txt (line 10)) (3.9.1)\n","Collecting responses<0.19 (from datasets~=2.12.0->-r requirements.txt (line 10))\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting portalocker (from sacrebleu->-r requirements.txt (line 12))\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r requirements.txt (line 12)) (0.9.0)\n","Collecting colorama (from sacrebleu->-r requirements.txt (line 12))\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.12.0->-r requirements.txt (line 10)) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.12.0->-r requirements.txt (line 10)) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.12.0->-r requirements.txt (line 10)) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.12.0->-r requirements.txt (line 10)) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.12.0->-r requirements.txt (line 10)) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.12.0->-r requirements.txt (line 10)) (4.0.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8,>=5.3.4->notebook->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook->-r requirements.txt (line 5)) (4.0.0)\n","Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->-r requirements.txt (line 5)) (1.24.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->-r requirements.txt (line 5)) (0.2.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (4.11.2)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (0.4)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (0.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (2.1.3)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (0.9.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (1.5.0)\n","Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (2.16.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 5)) (1.2.1)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->-r requirements.txt (line 5)) (2.19.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->-r requirements.txt (line 5)) (4.19.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 8)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 8)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 8)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 8)) (2023.11.17)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->-r requirements.txt (line 5)) (0.7.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->-r requirements.txt (line 5)) (21.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->notebook->-r requirements.txt (line 5)) (7.34.0)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","Collecting multiprocess (from datasets~=2.12.0->-r requirements.txt (line 10))\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets~=2.12.0->-r requirements.txt (line 10)) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->-r requirements.txt (line 9)) (1.3.0)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5)) (3.0.41)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5)) (4.9.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 5)) (2023.11.2)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 5)) (0.31.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 5)) (0.13.2)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->-r requirements.txt (line 5)) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->-r requirements.txt (line 5)) (1.6.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client<8,>=5.3.4->notebook->-r requirements.txt (line 5)) (1.16.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 5)) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook->-r requirements.txt (line 5)) (2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook->-r requirements.txt (line 5)) (0.5.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->-r requirements.txt (line 5)) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->-r requirements.txt (line 5)) (1.2.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 5)) (2.21)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5)) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 5)) (0.2.12)\n","Building wheels for collected packages: jupyter_contrib_nbextensions, jupyter_contrib_core\n","  Building wheel for jupyter_contrib_nbextensions (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jupyter_contrib_nbextensions: filename=jupyter_contrib_nbextensions-0.7.0-py2.py3-none-any.whl size=23428782 sha256=3b421da850c119fec21aec9618c265c51a2c0402d0005f62423e196dd4293557\n","  Stored in directory: /root/.cache/pip/wheels/ea/cc/7d/99ef154f984726b1201c0f72cfe9c9d7c5132c1a2ae4d8677f\n","  Building wheel for jupyter_contrib_core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jupyter_contrib_core: filename=jupyter_contrib_core-0.4.2-py2.py3-none-any.whl size=17483 sha256=a8755ccb164fc170697dddb33478b8649acb8f075e011f71b5a4aab4d8f0221f\n","  Stored in directory: /root/.cache/pip/wheels/a9/52/88/e0643cdfd68f0562087918c37dd583378648dbc3df68b907f7\n","Successfully built jupyter_contrib_nbextensions jupyter_contrib_core\n","Installing collected packages: jupyter_highlight_selected_word, portalocker, jedi, dill, colorama, sacrebleu, responses, multiprocess, accelerate, datasets, peft, jupyter_contrib_core, jupyter_nbextensions_configurator, jupyter_contrib_nbextensions\n","Successfully installed accelerate-0.25.0 colorama-0.4.6 datasets-2.12.0 dill-0.3.6 jedi-0.19.1 jupyter_contrib_core-0.4.2 jupyter_contrib_nbextensions-0.7.0 jupyter_highlight_selected_word-0.2.0 jupyter_nbextensions_configurator-0.6.3 multiprocess-0.70.14 peft-0.7.0 portalocker-2.8.2 responses-0.18.0 sacrebleu-2.3.3\n"]}]},{"cell_type":"code","source":["import argparse, os, string, sys\n","import torch\n","import sacrebleu\n","from tqdm import tqdm\n","from pathlib import Path\n","from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from peft import PrefixTuningConfig, get_peft_model, TaskType\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from peft import PeftModel\n","import torch.nn.functional as F\n","import pandas as pd"],"metadata":{"id":"kRCglGT6MmRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"AlB034pmNKME"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Form & Consolidate Dataset"],"metadata":{"id":"0oG0bKYFKq99"}},{"cell_type":"code","source":["import pandas as pd\n","\n","dfs = []\n","\n","file_paths = ['data/quest_dataset_up_to_kalimdor.csv', 'data/quest_dataset_kalimdor_to_profession.csv','data/quest_dataset_profession_to_end.csv', 'data/quest_dataset_wotlk.csv', 'data/quest_dataset_classic.csv']\n","for file_path in file_paths:\n","  df = pd.read_csv(file_path)\n","  df.columns = [\"id\", \"name\", \"objective\", \"description\"]\n","  dfs.append(df)\n","combined_df = pd.concat(dfs, ignore_index=True)\n","df = combined_df\n","df.columns = [\"id\", \"name\", \"objective\", \"description\"]\n","\n","df = df.drop(columns=['id'])\n","\n","rows_to_remove = []\n","\n","# Loop through each row and check for the \"�\" character in 'objective' or 'description' columns\n","for index, row in df.iterrows():\n","    if \"�\" in row['objective'] or \"�\" in row['description']:\n","        print(\"row has quest thingy! \" + str(index))\n","        rows_to_remove.append(index)\n","\n","    # print(row['description'])\n","\n","# Remove the identified rows from the DataFrame\n","df_cleaned = df.drop(rows_to_remove)\n","\n","df = df_cleaned\n","\n","df = df.drop_duplicates(keep='first')\n","\n","# Reorder the indices of the DataFrame\n","df.reset_index(drop=True, inplace=True)\n","\n","# Transform the dataset according to the specified format\n","def format_quest_input(row):\n","    title = f\"Name: {row['name']}\"\n","    objective = f\"Objective: {row['objective']} \"\n","    return f\"{title}, {objective}\"\n","\n","def format_quest_output(row):\n","    description = f\"{row['description']}\"\n","    return f\"{description}\"\n","\n","df['meaning_representation'] = df.apply(format_quest_input, axis=1)\n","df['quest_description'] = df.apply(format_quest_output, axis=1)\n","\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UMAznC50G_Zq","executionInfo":{"status":"ok","timestamp":1702150780884,"user_tz":480,"elapsed":7303,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"f06a373f-f1d2-457e-e262-5e7cfc2c31c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-570f03dd8f6c>:49: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['meaning_representation'] = df.apply(format_quest_input, axis=1)\n","<ipython-input-7-570f03dd8f6c>:50: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['quest_description'] = df.apply(format_quest_output, axis=1)\n"]},{"output_type":"execute_result","data":{"text/plain":["                      name                                          objective  \\\n","0             Murloc Motes                          Drain 12 Temporal Motes.    \n","1      Deathwingurlugull!   Get in the Hopper and defeat Deathwingurlugull...   \n","2           Mugurlglrlgl!    Murglgulglrrlglgul! A level 68 Azmerloth Quest.    \n","3      The Storm Race Tour  Fly each of the Storm Race courses around the ...   \n","4         Out For Delivery  Tell Cataloger Wulferd in the nearby basecamp ...   \n","...                    ...                                                ...   \n","22538    Major Mana Potion  In addition to our other supplies, we also hav...   \n","22539             <UNUSED>  Go to Tarren Mill and find out the status of t...   \n","22540             <UNUSED>                            Talk to Kelt Thomasin.    \n","22541      Test Kill Quest  Kill 5 Murlocs and come back to the test chara...   \n","22542             <UNUSED>  Collect 5 Threshadon Teeth and 5 Threshadon Cl...   \n","\n","                                             description  \\\n","0      An alternate timeline born from murlocs? ? !\\r...   \n","1      Deathwingurlugull! Deathwingurlugull! Deathwin...   \n","2      Mrglgulglrrlglgul! Grurguglullgurl!\\r\\n\\r\\nGru...   \n","3      This storm gryphon is intriguing! Whatever lan...   \n","4      I tried to tell Vevesi that I could pull the w...   \n","...                                                  ...   \n","22538  Here you are, <name>. Be careful out there. Ou...   \n","22539  As a child, raised as a gladiator at Durnholde...   \n","22540  Hello there, <name>. I've heard much about you...   \n","22541  Got some time to spare?  Kill me some Murlocs ...   \n","22542  Now, this will no doubt convince you that I am...   \n","\n","                                  meaning_representation  \\\n","0      Name: Murloc Motes, Objective: Drain 12 Tempor...   \n","1      Name: Deathwingurlugull! , Objective: Get in t...   \n","2      Name: Mugurlglrlgl! , Objective: Murglgulglrrl...   \n","3      Name: The Storm Race Tour, Objective: Fly each...   \n","4      Name: Out For Delivery, Objective: Tell Catalo...   \n","...                                                  ...   \n","22538  Name: Major Mana Potion, Objective: In additio...   \n","22539  Name: <UNUSED>, Objective: Go to Tarren Mill a...   \n","22540  Name: <UNUSED>, Objective: Talk to Kelt Thomas...   \n","22541  Name: Test Kill Quest, Objective: Kill 5 Murlo...   \n","22542  Name: <UNUSED>, Objective: Collect 5 Threshado...   \n","\n","                                       quest_description  \n","0      An alternate timeline born from murlocs? ? !\\r...  \n","1      Deathwingurlugull! Deathwingurlugull! Deathwin...  \n","2      Mrglgulglrrlglgul! Grurguglullgurl!\\r\\n\\r\\nGru...  \n","3      This storm gryphon is intriguing! Whatever lan...  \n","4      I tried to tell Vevesi that I could pull the w...  \n","...                                                  ...  \n","22538  Here you are, <name>. Be careful out there. Ou...  \n","22539  As a child, raised as a gladiator at Durnholde...  \n","22540  Hello there, <name>. I've heard much about you...  \n","22541  Got some time to spare?  Kill me some Murlocs ...  \n","22542  Now, this will no doubt convince you that I am...  \n","\n","[22543 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-45aaf8f1-40e1-403f-ba3a-c71728e34036\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>objective</th>\n","      <th>description</th>\n","      <th>meaning_representation</th>\n","      <th>quest_description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Murloc Motes</td>\n","      <td>Drain 12 Temporal Motes.</td>\n","      <td>An alternate timeline born from murlocs? ? !\\r...</td>\n","      <td>Name: Murloc Motes, Objective: Drain 12 Tempor...</td>\n","      <td>An alternate timeline born from murlocs? ? !\\r...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Deathwingurlugull!</td>\n","      <td>Get in the Hopper and defeat Deathwingurlugull...</td>\n","      <td>Deathwingurlugull! Deathwingurlugull! Deathwin...</td>\n","      <td>Name: Deathwingurlugull! , Objective: Get in t...</td>\n","      <td>Deathwingurlugull! Deathwingurlugull! Deathwin...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mugurlglrlgl!</td>\n","      <td>Murglgulglrrlglgul! A level 68 Azmerloth Quest.</td>\n","      <td>Mrglgulglrrlglgul! Grurguglullgurl!\\r\\n\\r\\nGru...</td>\n","      <td>Name: Mugurlglrlgl! , Objective: Murglgulglrrl...</td>\n","      <td>Mrglgulglrrlglgul! Grurguglullgurl!\\r\\n\\r\\nGru...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The Storm Race Tour</td>\n","      <td>Fly each of the Storm Race courses around the ...</td>\n","      <td>This storm gryphon is intriguing! Whatever lan...</td>\n","      <td>Name: The Storm Race Tour, Objective: Fly each...</td>\n","      <td>This storm gryphon is intriguing! Whatever lan...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Out For Delivery</td>\n","      <td>Tell Cataloger Wulferd in the nearby basecamp ...</td>\n","      <td>I tried to tell Vevesi that I could pull the w...</td>\n","      <td>Name: Out For Delivery, Objective: Tell Catalo...</td>\n","      <td>I tried to tell Vevesi that I could pull the w...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>22538</th>\n","      <td>Major Mana Potion</td>\n","      <td>In addition to our other supplies, we also hav...</td>\n","      <td>Here you are, &lt;name&gt;. Be careful out there. Ou...</td>\n","      <td>Name: Major Mana Potion, Objective: In additio...</td>\n","      <td>Here you are, &lt;name&gt;. Be careful out there. Ou...</td>\n","    </tr>\n","    <tr>\n","      <th>22539</th>\n","      <td>&lt;UNUSED&gt;</td>\n","      <td>Go to Tarren Mill and find out the status of t...</td>\n","      <td>As a child, raised as a gladiator at Durnholde...</td>\n","      <td>Name: &lt;UNUSED&gt;, Objective: Go to Tarren Mill a...</td>\n","      <td>As a child, raised as a gladiator at Durnholde...</td>\n","    </tr>\n","    <tr>\n","      <th>22540</th>\n","      <td>&lt;UNUSED&gt;</td>\n","      <td>Talk to Kelt Thomasin.</td>\n","      <td>Hello there, &lt;name&gt;. I've heard much about you...</td>\n","      <td>Name: &lt;UNUSED&gt;, Objective: Talk to Kelt Thomas...</td>\n","      <td>Hello there, &lt;name&gt;. I've heard much about you...</td>\n","    </tr>\n","    <tr>\n","      <th>22541</th>\n","      <td>Test Kill Quest</td>\n","      <td>Kill 5 Murlocs and come back to the test chara...</td>\n","      <td>Got some time to spare?  Kill me some Murlocs ...</td>\n","      <td>Name: Test Kill Quest, Objective: Kill 5 Murlo...</td>\n","      <td>Got some time to spare?  Kill me some Murlocs ...</td>\n","    </tr>\n","    <tr>\n","      <th>22542</th>\n","      <td>&lt;UNUSED&gt;</td>\n","      <td>Collect 5 Threshadon Teeth and 5 Threshadon Cl...</td>\n","      <td>Now, this will no doubt convince you that I am...</td>\n","      <td>Name: &lt;UNUSED&gt;, Objective: Collect 5 Threshado...</td>\n","      <td>Now, this will no doubt convince you that I am...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>22543 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45aaf8f1-40e1-403f-ba3a-c71728e34036')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-45aaf8f1-40e1-403f-ba3a-c71728e34036 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-45aaf8f1-40e1-403f-ba3a-c71728e34036');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-94015762-bdf3-4432-841b-fd5fa635e858\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94015762-bdf3-4432-841b-fd5fa635e858')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-94015762-bdf3-4432-841b-fd5fa635e858 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_cfa449fb-92e9-425a-a622-d1f696fe34e9\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_cfa449fb-92e9-425a-a622-d1f696fe34e9 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Save the transformed dataset to a new CSV file\n","output_file_path_train = 'formatted_data_tagged_prefix_train.csv'\n","output_file_path_test = 'formatted_data_tagged_prefix_test.csv'\n","\n","from sklearn.model_selection import train_test_split\n","\n","df2 = df[['meaning_representation', 'quest_description']]\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","train.to_csv(output_file_path_train, index=False, header=True)\n","test.to_csv(output_file_path_test, index=False, header=True)\n","\n","output_file_path_train\n","output_file_path_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"YMt_t3qHHDof","executionInfo":{"status":"ok","timestamp":1702150785267,"user_tz":480,"elapsed":1662,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"98cba111-5b02-43ca-f5a4-2c930db1b205"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'formatted_data_tagged_prefix_test.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### Load Dataset for HuggingFace"],"metadata":{"id":"ZI8Z7Vq4KziK"}},{"cell_type":"code","source":["import pandas as pd\n","from datasets import Dataset\n","\n","# Load the dataset\n","dataset_path = 'formatted_data_tagged_prefix_train.csv'\n","df = pd.read_csv(dataset_path)\n","\n","# Convert DataFrame to Hugging Face Dataset\n","hf_dataset = Dataset.from_pandas(df)"],"metadata":{"id":"jWWpL1tGJvpG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hf_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-9Of7owJ6_R","executionInfo":{"status":"ok","timestamp":1702150790957,"user_tz":480,"elapsed":2,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"b0bbfe9e-196e-49ec-c58e-e7de8b683ea3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['meaning_representation', 'quest_description'],\n","    num_rows: 20288\n","})"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### Homework code"],"metadata":{"id":"c7g7li9QLuRw"}},{"cell_type":"code","source":["#@title Quest Generator (from Homework 4 - Prefix Tune & TableToText)\n","\n","class QuestGenerator:\n","\n","    def __init__(\n","            self,\n","            modelfile,\n","            modelsuffix='.pt',\n","            basemodel='distilgpt2',\n","            epochs=5,\n","            batchsize=4,\n","            lr=5e-5,\n","            virtualtokens=5,\n","            prefixprojection=False,\n","        ):\n","        # the input sentences will be handled using this object, you do not need to manually encode input sentence words\n","        self.tokenizer = AutoTokenizer.from_pretrained(basemodel)\n","        self.tokenizer_pad_token_id = self.tokenizer.eos_token_id \\\n","            if self.tokenizer.pad_token_id is None else self.tokenizer.pad_token_id\n","        self.modelfile = modelfile\n","        self.modelsuffix = modelsuffix\n","        self.basemodel = basemodel\n","        self.epochs = epochs\n","        self.batchsize = batchsize\n","        self.lr = lr\n","        self.virtualtokens = virtualtokens\n","        self.prefixprojection = prefixprojection\n","        self.prompt = \"Generate a description for the following video game quest: \"\n","        self.training_data = []\n","        self.model = None # setup the model in self.decode() or self.train()\n","\n","    def preprocess_function(self, examples):\n","\n","        text_column = \"meaning_representation\"\n","        label_column = \"quest_description\"\n","\n","        max_length = 128\n","        batch_size = len(examples[text_column])\n","        inputs = [f\"{self.prompt}{x} {self.tokenizer.bos_token} \" for x in examples[text_column]]\n","        targets = [f\"{x} {self.tokenizer.eos_token}\" for x in examples[label_column]]\n","\n","        model_inputs = self.tokenizer(inputs)\n","        labels = self.tokenizer(targets)\n","\n","        for i in range(batch_size):\n","            sample_input_ids = model_inputs[\"input_ids\"][i]\n","            label_input_ids = labels[\"input_ids\"][i] + [self.tokenizer_pad_token_id]\n","            model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n","            labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n","            model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n","        for i in range(batch_size):\n","            sample_input_ids = model_inputs[\"input_ids\"][i]\n","            label_input_ids = labels[\"input_ids\"][i]\n","            model_inputs[\"input_ids\"][i] = [self.tokenizer_pad_token_id] * (\n","                    max_length - len(sample_input_ids)\n","            ) + sample_input_ids\n","            model_inputs[\"attention_mask\"][i] = \\\n","                [0] * \\\n","                (max_length - len(sample_input_ids)) + \\\n","                model_inputs[\"attention_mask\"][i]\n","            labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n","            model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n","            model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n","            labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n","\n","        model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","        return model_inputs\n","\n","    def get_data(self, hf_dataset):\n","        \"\"\"\n","        Loads the requested dataset with name == :param dataset_name: and returns dataloaders over each split defined\n","          in :param splits: which can contain any subset of (\"train\", \"validation\", \"test\"). The dataloder batchsize will be\n","            defined using :param self.batchsize:.\n","        \"\"\"\n","        processed_dataset = hf_dataset.map(\n","            self.preprocess_function,\n","            batched=True,\n","            num_proc=1,\n","            load_from_cache_file=False,\n","            desc=\"Running tokenizer on dataset\"\n","        )\n","\n","        data_loader = DataLoader(\n","                                processed_dataset,\n","                                collate_fn=default_data_collator,\n","                                batch_size=self.batchsize,\n","                                pin_memory=True,\n","                                shuffle=True\n","                              )\n","        return data_loader\n","\n","    def train(self, hf_dataset_train):\n","\n","        data_loaders = {\"train\":self.get_data(hf_dataset_train)}\n","\n","        model = AutoModelForCausalLM.from_pretrained(self.basemodel)\n","\n","        prefix_config = PrefixTuningConfig(\n","            task_type=TaskType.CAUSAL_LM,\n","            num_virtual_tokens=self.virtualtokens,\n","            prefix_projection=self.prefixprojection\n","        )\n","        model = get_peft_model(model, prefix_config)\n","\n","        model.print_trainable_parameters()\n","\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr)\n","        lr_scheduler = get_linear_schedule_with_warmup(\n","            optimizer=optimizer,\n","            num_warmup_steps=0,\n","            num_training_steps=(len(data_loaders[\"train\"]) * self.epochs),\n","        )\n","        model = model.to(device)\n","\n","        for epoch in range(self.epochs):\n","            model.train()\n","\n","            # TODO rest of the training steps for prefix tuning\n","            total_loss = 0\n","            for batch in tqdm(data_loaders[\"train\"]):\n","              batch = {k: v.to(device) for k, v in batch.items()}\n","\n","              outputs = model(**batch)\n","              loss = outputs.loss\n","              total_loss += loss.item()\n","\n","              optimizer.zero_grad()\n","              loss.backward()\n","              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","              optimizer.step()\n","              lr_scheduler.step()\n","\n","            print(f\"Epoch {epoch}: Average Loss = {total_loss / len(data_loaders['train'])}\")\n","\n","            if epoch == self.epochs - 1:\n","                epoch_str = '' # last epoch so do not use epoch number in model filename\n","            else:\n","                epoch_str = str(epoch)\n","\n","            savefile = self.modelfile + epoch_str + self.modelsuffix\n","            model.save_pretrained(savefile)\n"],"metadata":{"id":"wLHrD_uRGeHs","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train:"],"metadata":{"id":"T9ZLTNH6LlGH"}},{"cell_type":"code","source":["from peft import PeftModel\n","\n","model_name = 'gpt2-medium'\n","model_suffix = '.pt'\n","\n","modelfile = os.path.join('data', 'peft_128')\n","if modelfile.endswith('.pt'):\n","    modelfile = modelfile.removesuffix('.pt')\n","quest_generator = QuestGenerator(\n","                    modelfile,\n","                    modelsuffix='.pt',\n","                    basemodel=model_name,\n","                    epochs=1,\n","                    batchsize=4,\n","                    lr=5e-5,\n","                    virtualtokens=8,\n","                    prefixprojection=True\n","                )\n","quest_generator.train(hf_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["fb5707380a6643d59a3adf1de3eeaf79","3fc8f74a53b3447db2a26063e9902103","bd74400f2e5f46cfa8b472dee86e5411","147f9146e3a24eb98bb4368ea4cfb178","9d746af7be204a95b6f31e1237c9452e","99bd03b7b4064978b33e69943055630d","8bb89b4d3e1b4df7a132da38caa468ed","c9bee314105448e6beccdd749ef264cc","4027283d0a0748b3bd14826d91c914dc","b9b0ad38f8664382a3f9b8d7b095b0e4","209032751cc6493b8dbfa3a44ed65588"]},"id":"G9BB220HBlGl","executionInfo":{"status":"ok","timestamp":1702157581938,"user_tz":480,"elapsed":1427326,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"cac6a97b-ec71-4f2b-f34a-d0e91e000f9f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Running tokenizer on dataset:   0%|          | 0/20288 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5707380a6643d59a3adf1de3eeaf79"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["trainable params: 51,438,592 || all params: 406,261,760 || trainable%: 12.661440742047688\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5072/5072 [23:27<00:00,  3.60it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 0: Average Loss = 2.986790826808579\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["### Evaluate:"],"metadata":{"id":"A1juzoEBK-TM"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('gpt2-medium')\n","tokenizer_pad_token_id = tokenizer.eos_token_id \\\n","  if tokenizer.pad_token_id is None else tokenizer.pad_token_id\n","model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n","\n","# make sure you have a model file to access\n","modelfile = os.path.join('data', 'pt_gpt2_medium_128_length')\n","model_suffix = '.pt'\n","\n","model = PeftModel.from_pretrained(model, modelfile + model_suffix)\n","model.eval()\n","model = model.to(device)  # Move model to the device"],"metadata":{"id":"rulwQaX055UG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.special_tokens_map"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IcMwcKAa9LX7","executionInfo":{"status":"ok","timestamp":1702203052101,"user_tz":480,"elapsed":12,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"9a49698d-a637-40ee-b892-53575f922dfb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bos_token': '<|endoftext|>',\n"," 'eos_token': '<|endoftext|>',\n"," 'unk_token': '<|endoftext|>'}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["sentence = f\"Generate a description for the following video game quest: Name: Water Ways, Objective: Kill all the Ogres by the river, near the town of Algredon. <|endoftext|> \""],"metadata":{"id":"b0DLPt0gLCK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Single Prompt\n","\n","import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","import torch.nn.functional as F\n","\n","# Check if GPU is available and set the device accordingly\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","context_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n","context = torch.tensor(context_tokens, dtype=torch.long, device=device)  # Move tensor to the device\n","num_samples = 1\n","context = context.unsqueeze(0).repeat(num_samples, 1)\n","generated = context\n","\n","eos_token_id = tokenizer.eos_token_id\n","\n","length = 128\n","temperature = 0.7  # Temperature parameter\n","top_k = 120\n","\n","with torch.no_grad():\n","    for _ in range(length):\n","        outputs = model(generated)\n","        next_token_logits = outputs.logits[:, -1, :] / (temperature if temperature > 0 else 1.)\n","\n","        # Filter the logits to only include top-k options\n","        top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n","        probabilities = F.softmax(top_k_logits, dim=-1)\n","\n","        # Sample from the filtered distribution\n","        next_token = torch.multinomial(probabilities, num_samples=1)\n","        next_token = top_k_indices.gather(-1, next_token)\n","        if next_token.item() == eos_token_id | next_token.item() == tokenizer.bos_token_id:\n","            break\n","        generated = torch.cat((generated, next_token.to(device)), dim=1)  # Ensure next_token is on the same device\n","\n","out = generated\n","out = out[:, len(context_tokens):].tolist()\n","for o in out:\n","    text = tokenizer.decode(o, clean_up_tokenization_spaces=False)\n","    print(text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q43kCWtq0gkW","executionInfo":{"status":"ok","timestamp":1702203079506,"user_tz":480,"elapsed":6974,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"0824fe67-4816-4650-a92a-c6d6e5b1ed0c","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Algredon is a city of stone, filled with high-fliers and few goodly creatures. We will not risk our lives here, <name>.  \r\n","\r\n","The Ogres are here to drink the river's blood.�\n","\r\n","No, I do not mean to take them out of sight. \r\n","\r\n","I am asking you to do what only the bravest of us would do. \r\n","\r\n","Take our place and help.  \n"]}]},{"cell_type":"code","source":["#@title Run Test File\n","\n","dataset_test_path = 'formatted_data_tagged_prefix_test.csv'\n","df_test = pd.read_csv(dataset_test_path)\n","df_test.columns = ['sentence', 'output']\n","\n","prompt = \"Generate a description for the following video game quest: \"\n","\n","references = []\n","preds = []\n","\n","max_step = 500\n","\n","for i, sentence in enumerate(df_test['sentence']):\n","    p = prompt + sentence + \"<|endoftext|>\"\n","    # print(\"prompt: {}\".format(p))\n","    context_tokens = tokenizer.encode(sentence, add_special_tokens=True)\n","    context = torch.tensor(context_tokens, dtype=torch.long, device=device)  # Move tensor to the device\n","    num_samples = 1\n","    context = context.unsqueeze(0).repeat(num_samples, 1)\n","    generated = context\n","\n","    eos_token_id = tokenizer.eos_token_id\n","\n","    length = 128\n","    temperature = 0.9  # Temperature parameter\n","    top_k = 100\n","\n","    with torch.no_grad():\n","        for _ in range(length):\n","            outputs = model(generated)\n","            next_token_logits = outputs.logits[:, -1, :] / (temperature if temperature > 0 else 1.)\n","\n","            # Filter the logits to only include top-k options\n","            top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n","            probabilities = F.softmax(top_k_logits, dim=-1)\n","\n","            # Sample from the filtered distribution\n","            next_token = torch.multinomial(probabilities, num_samples=1)\n","            next_token = top_k_indices.gather(-1, next_token)\n","            if next_token.item() == eos_token_id | next_token.item() == tokenizer.bos_token_id:\n","                break\n","            generated = torch.cat((generated, next_token.to(device)), dim=1)  # Ensure next_token is on the same device\n","\n","    out = generated\n","    out = out[:, len(context_tokens):].tolist()\n","    for o in out:\n","        text = tokenizer.decode(o, clean_up_tokenization_spaces=False)\n","\n","        references.append(df_test['output'][i])\n","        preds.append(text)\n","\n","        print(text)\n","\n","        break\n","\n","    if i >= max_step:\n","      break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":775},"id":"aFbKx5fO7hz_","executionInfo":{"status":"error","timestamp":1702203151531,"user_tz":480,"elapsed":14969,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"b7d24954-680e-4cea-e5ee-ea2945a44835","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["These are some extremely dangerous demons. \r\n","\r\n","The battle to repel them is at hand.\r\n","\r\n","We must see to their immediate defense to ensure victory.\r\n","\r\n","My people have developed an advanced defensive device: the \"Vindicaar\" - an oversized shield that will protect them from all attacks.\r\n","\r\n","It is far from perfect, but we can afford to lose it if we are going to stand a chance.\r\n","\r\n","I will go back to the Vindicaar and see this through.  \n","Now you see, it's the first time I've seen a gift from you. I have for you a single item, with a message that speaks volumes. rawdownload\n","\n","The Gift of the Huntress is meant to prepare you for adventure. If the task is answered, the Gift will be consumed.\n","\n","Your sacrifice will help me bring the Horde's ancient enemies to heel.\n","\n","I want you to prove me right. \n","\n","I shall reward you with all of the fame that awaits you for your efforts.  \n","Now, the power to summon these artifacts may be found nearby you in the cavern, but there is a larger piece of ancient information hidden within them. Here is where you will find this ancient artifact's brain. Go into Shifting Beacons and gain entry to the Hive'Zora Silithid Brain. Inside its brain, you should find an ancient hive'ashi silithid brain, a hive'regal silithid brain, and a hive'zora silithid brain.  \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-bfcf346ad28a>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeft_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPeftType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREFIX_TUNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mpast_key_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m             return self.base_model(\n\u001b[0m\u001b[1;32m   1107\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1075\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    886\u001b[0m                 )\n\u001b[1;32m    887\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    889\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresid_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["for i, pred in enumerate(preds):\n","  print(\"---> prompt: {}\".format(df_test['sentence'][i]))\n","  print(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVUZsKHOxsyP","executionInfo":{"status":"ok","timestamp":1702163707597,"user_tz":480,"elapsed":401,"user":{"displayName":"VEN 1","userId":"05216858692085773250"}},"outputId":"666e6aa4-c5ec-42ea-a0f5-6ea06212e838"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---> prompt: Name: Return to the Vindicaar, Objective: Return to the Vindicaar.  \n","Generate a description for the following video game quest: Name: Return to the Vindicaar, Objective: Return to the Vindicaar.  <|endoftext|>There are many such things as that: the Burning Legion's presence haunts the whole of Azeroth, and the remnants of the original Horde have turned on one another.\r\n","\r\n","The Burning Legion has brought it down to this, so I trust you can do something to help them.\r\n","\r\n","I do not speak for the rest of the Vindicaar, but I do know they are ready to aid in any way you need them to.  \n","---> prompt: Name: Blingtron 7000, Objective: OUTPUT: Please accept this GIFT.  \n","Generate a description for the following video game quest: Name: Blingtron 7000, Objective: OUTPUT: Please accept this GIFT.  <|endoftext|>If you've ever made the pilgrimage to the Ruins of Orgrimmar, chances are you've heard of the Dragonblight. A plague which has ravaged the Horde's borders, spawning a terrible plague of undeath, blighting the lands of Azeroth - the Burning Legion. The Horde has destroyed its own power to the north, and is trying to reclaim its lost glory in the form of the dreaded Dragonblight. The Horde has erected numerous defenses against the Legion's invasion force. Perhaps this is why we have so few refugees to do our dirty work.  \n"]}]},{"cell_type":"code","source":["#@title Export\n","\n","import csv\n","\n","if not os.path.exists('output'):\n","    os.makedirs('output')\n","\n","csv_file_path = 'output/formatted_dataset_tagged_prefix_test_out.csv'\n","\n","# Write the list to a CSV file\n","with open(csv_file_path, 'w', newline='') as csvfile:\n","    csv_writer = csv.writer(csvfile)\n","\n","    # Writing each string as a new row\n","    for string in outputs:\n","        csv_writer.writerow([string])\n","\n","print(f\"List of strings written to {csv_file_path}\")"],"metadata":{"id":"vf8SFslON3Ac"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[{"file_id":"1nXc1xgVwG94Kd2a85I7DmPIvKeP-KKxF","timestamp":1702149496078},{"file_id":"17zDmni7k6w8WA4ZfrUcpYkUt4E6jyI3d","timestamp":1701994434704}],"gpuType":"T4","collapsed_sections":["7wz9IqvpKnZE","0oG0bKYFKq99","ZI8Z7Vq4KziK","c7g7li9QLuRw","T9ZLTNH6LlGH"]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fb5707380a6643d59a3adf1de3eeaf79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fc8f74a53b3447db2a26063e9902103","IPY_MODEL_bd74400f2e5f46cfa8b472dee86e5411","IPY_MODEL_147f9146e3a24eb98bb4368ea4cfb178"],"layout":"IPY_MODEL_9d746af7be204a95b6f31e1237c9452e"}},"3fc8f74a53b3447db2a26063e9902103":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99bd03b7b4064978b33e69943055630d","placeholder":"​","style":"IPY_MODEL_8bb89b4d3e1b4df7a132da38caa468ed","value":"Running tokenizer on dataset: 100%"}},"bd74400f2e5f46cfa8b472dee86e5411":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9bee314105448e6beccdd749ef264cc","max":20288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4027283d0a0748b3bd14826d91c914dc","value":20288}},"147f9146e3a24eb98bb4368ea4cfb178":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9b0ad38f8664382a3f9b8d7b095b0e4","placeholder":"​","style":"IPY_MODEL_209032751cc6493b8dbfa3a44ed65588","value":" 20288/20288 [00:12&lt;00:00, 1675.18 examples/s]"}},"9d746af7be204a95b6f31e1237c9452e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"99bd03b7b4064978b33e69943055630d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bb89b4d3e1b4df7a132da38caa468ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9bee314105448e6beccdd749ef264cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4027283d0a0748b3bd14826d91c914dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9b0ad38f8664382a3f9b8d7b095b0e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"209032751cc6493b8dbfa3a44ed65588":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}